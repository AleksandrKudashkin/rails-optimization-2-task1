# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
  - Время выполнения метода work (Benchmark.realtime)

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 1 час

Вот как я построил `feedback_loop`: 
  - вынес будущий результат работы в отдельный класс `Refactored`
  - сделал сравнительный benchmark на тестовом объёме данных

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался следующими инструментами:
  - профайлер `rbspy`
  - профайлер `ruby-prof`, графики: `Flat`, `Graph`, `Callstack`, `Callgrind`

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- `ruby-prof` с отчетом типа `Flat` показал, что  89.31% времени уходит на `Array#select`
- `ruby-prof` с отчетом типа `Graph` и `Callstack` так же показывают, что 99% времени приходится на `Array.each`, который и вызывает `Array.select` в свою очередь

Вывод: основная точка роста - блок `sessions.select { .. }`
При большом количестве данных, каждый раз перебирать весь массив с сессиями неэффективно и увеличивает время исполнения сильно. В качестве решения я выбрал:
 - Заменить sessions на Hash с ключом в виде user_id и значениями в виде массива сессий этого пользователя
 - Обновить зависящие от sessions как массива места: 
   - total_sessions_count
   - unique_browsers
   - all_browsers

В результате сравнительный тест показал 16.42x прирост скорости на тестовых данных и realtime тест показал уменьшение времени исполнения с 4.89 sec до 0.31 sec

### Ваша находка №2
- `ruby-prof` с отчетом типа `Callstack` показал, что следующая точка роста `Array#.all?` в `parse_sessions`. Решение: заменить на структуру данных Set. 
- Сравнительный тест показал 19.77x прирост, время исполнения тестовых данных 0.244 sec

### Ваша находка №3
- Callstack показывает много вызовов `.map` в `collect_stats_from_users`. Я заметил, что мы каждый раз перебираем пользователей. Вынес этот перебор в один цикл.
Получил результаты: 22.35x прирост и 196 мс на тестовых данных

### Ваша находка №4
- Callstack показывает много вызовов `.map` в `collect_stats_from_users`. Я заметил, что мы каждый раз перебираем пользователей. Вынес этот перебор в один цикл.
Получил результаты: 22.35x прирост и 196 мс на тестовых данных
- Убрал создание класса с пользователями, убрал еще один цикл. Получил результаты: 26.26x и 186мс

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*

- Поставил TurboBoostSwitcher, настроил gemset, ruby-version, добавил Gemfile, .gitignore, установил rbspy, вынес тест в отдельный файл
- Попробовал rbspy на полном объеме данных, показывает 98% block in work, что не очень информативно. Попробую фидбек-луп выстроить сначала.
- Поставил kalibera, сделал data_bench.txt до 2000 сессий
- Вынес будущий рефактор в Refactored class, поменял тест, настроил сравнение оригиального метода и будущего рефактора через Benchmark ips
- Попробовал отключить GC, на моих тестовых данных разница в 0.7 секунды (700 ms) при Benchmark.realtime на 20000 строк
- Добавил бенчмарк зависимости. Похоже, что зависимость либо экспоненциальная либо квадратичная, не дожидаюсь окончания теста даже на небольшом объеме данных.

